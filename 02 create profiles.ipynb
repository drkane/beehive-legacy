{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = pd.read_pickle('proposals.pkl')\n",
    "themes = pd.read_pickle('themes.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_order = [\n",
    "    'North East',\n",
    "    'North West',\n",
    "    'Yorkshire and The Humber',\n",
    "    'East Midlands',\n",
    "    'West Midlands',\n",
    "    'East of England',\n",
    "    'London',\n",
    "    'South East',\n",
    "    'South West',\n",
    "    'England',\n",
    "    'Scotland',\n",
    "    'Wales',\n",
    "    'Northern Ireland',\n",
    "    'UK wide',\n",
    "    'Overseas',\n",
    "    'UK and overseas',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most common words for a dataset\n",
    "def most_common_words(df, n=10):\n",
    "    text = df[\n",
    "        ['title', 'description']\n",
    "    ].fillna(\"\")\\\n",
    "        .apply(\" \".join, axis=1)\\\n",
    "        .str.lower()\\\n",
    "        .map(lambda x: re.sub(' +', ' ', re.sub('[^ a-z0-9]', ' ', x)))\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    count_data = count_vectorizer.fit_transform(text)\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    total_counts = np.zeros(len(words))\n",
    "    for t in count_data:\n",
    "        total_counts+=t.toarray()[0]\n",
    "    \n",
    "    count_dict = (zip(words, total_counts))\n",
    "    count_dict = sorted(count_dict, key=lambda x:x[1], reverse=True)[0:n]\n",
    "    return dict(count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_profile(p, t):\n",
    "    areas = p['area'].value_counts().to_dict()\n",
    "    return {\n",
    "        'recipient_category': p['recipient_category'].value_counts().to_dict(),\n",
    "        'recipient_income_band': p['recipient_income_band'].value_counts().sort_index().to_dict(),\n",
    "        'recipient_operating_for': p['recipient_operating_for'].value_counts().sort_index().to_dict(),\n",
    "        'geographic_scale': p['geographic_scale'].value_counts().to_dict(),\n",
    "        'category': p['category'].value_counts().to_dict(),\n",
    "        'amount_stats': p['min_amount'].describe().to_dict(),\n",
    "        'amount_bins': p['amount_bins'].value_counts().sort_index().to_dict(),\n",
    "        'duration_bins': p['duration_bins'].value_counts().sort_index().to_dict(),\n",
    "        'area': {\n",
    "            r: areas.get(r, 0)\n",
    "            for r in region_order\n",
    "        },\n",
    "        'themes': t[t['proposal_id'].isin(p.index)]['parent_name'].value_counts().to_dict(),\n",
    "        'examples': p.loc[\n",
    "            (p.created_at.dt.year >= 2018) & (p.recipient_category != \"An individual\"),\n",
    "            [\"title\", \"description\", 'geographic_scale', \n",
    "            'recipient_operating_for', 'recipient_income_band', \n",
    "            'area', 'category', 'recipient_category', \n",
    "            'amount_bins', 'duration_bins']\n",
    "        ].sample(15).to_dict(orient='records'),\n",
    "        'word_counts': most_common_words(p, n=30)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "East of England\n",
      "Scotland\n",
      "South West\n",
      "West Midlands\n",
      "North West\n",
      "Overseas\n",
      "North East\n",
      "England\n",
      "South East\n",
      "UK and overseas\n",
      "East Midlands\n",
      "Wales\n",
      "Yorkshire and The Humber\n",
      "London\n",
      "UK wide\n",
      "Northern Ireland\n",
      "Education and training\n",
      "Public and societal benefit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\drkan\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexing.py:1418: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health and medicine\n",
      "Social welfare\n",
      "Crime and justice\n",
      "Employment\n",
      "Climate and the environment\n",
      "Community improvement and capacity building\n",
      "International and foreign affairs\n",
      "Arts and recreation\n",
      "Science and technology\n"
     ]
    }
   ],
   "source": [
    "t = themes[themes['parent_name']!=\"Groups\"]\n",
    "results = {\n",
    "    \"area\": {},\n",
    "    \"theme\": {},\n",
    "}\n",
    "\n",
    "# full dataset\n",
    "results['all'] = create_profile(proposals, t)\n",
    "\n",
    "# by area\n",
    "for k in proposals.area.dropna().unique():\n",
    "    print(k)\n",
    "    results['area'][k] = create_profile(proposals[proposals.area==k], t)\n",
    "\n",
    "# by theme\n",
    "for k in t['parent_name'].unique():\n",
    "    print(k)\n",
    "    p = proposals.loc[themes.loc[themes['parent_name']==k, 'proposal_id'], :]\n",
    "    results['theme'][k] = create_profile(p, t)\n",
    "\n",
    "# add existing examples\n",
    "with open('docs/results.json', 'r') as b:\n",
    "    existing_results = json.load(b)\n",
    "    results['all']['examples'] = existing_results['all']['examples']\n",
    "    for k in ['area', 'theme']:\n",
    "        for p in results[k]:\n",
    "            if existing_results[k].get(p, {}).get('examples'):\n",
    "                results[k][p]['examples'] = existing_results[k][p]['examples']\n",
    "    \n",
    "with open('docs/results.json', 'w') as a:\n",
    "    json.dump(results, a, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015       45\n",
       "2016     4400\n",
       "2017    10225\n",
       "2018     6174\n",
       "2019     1982\n",
       "2020      530\n",
       "Name: created_at, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals.created_at.dt.year.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
